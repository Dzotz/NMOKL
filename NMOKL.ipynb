{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499f0e5b-6483-4be3-b804-8781caca32f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.0\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983648df-05d5-4e8b-96db-ab2361206ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.8.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.8.0)\n",
      "Requirement already satisfied: torchtext==0.9.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.9.0)\n",
      "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.4.3)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torch==1.8.0) (4.4.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torch==1.8.0) (1.23.5)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torchtext==0.9.0) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torchtext==0.9.0) (4.64.1)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (41.2.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (1.10.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (8.1.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->torchtext==0.9.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->torchtext==0.9.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->torchtext==0.9.0) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->torchtext==0.9.0) (1.26.13)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (6.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 22.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.8.0 torchtext==0.9.0 spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "024ff24f-1ccb-4903-a1a3-7275b224c8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n",
      "0.9.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "print(torch.__version__)\n",
    "import torchtext\n",
    "print(torchtext.__version__)\n",
    "\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37142a08-a1a2-4d4d-bcd4-ea3876aac42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8168a1e0-99a5-44b0-85f6-d712528fe498",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower = True)\n",
    "UD_TAGS = data.Field(unk_token = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68bd3a0f-04f9-4986-aef4-50e4dbebac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ((\"text\", TEXT), (\"udtags\", UD_TAGS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cd30620-afd5-4b91-9fae-d58753d5b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = datasets.UDPOS.splits(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2af656bf-e342-4808-9bfb-17a41d567b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 12543\n",
      "Number of validation examples: 2002\n",
      "Number of testing examples: 2077\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data)}\")\n",
    "print(f\"Number of testing examples: {len(test_data)}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81079385-6ab3-41cd-90da-6c3be4adfbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_FREQ = 2\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 min_freq = MIN_FREQ,\n",
    "                 vectors = \"glove.6B.100d\",\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "\n",
    "UD_TAGS.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e264f54-c67e-4d9b-996b-cc692f294541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag\t\tCount\t\tPercentage\n",
      "\n",
      "NOUN\t\t34781\t\t17.0%\n",
      "PUNCT\t\t23679\t\t11.6%\n",
      "VERB\t\t23081\t\t11.3%\n",
      "PRON\t\t18577\t\t 9.1%\n",
      "ADP\t\t17638\t\t 8.6%\n",
      "DET\t\t16285\t\t 8.0%\n",
      "PROPN\t\t12946\t\t 6.3%\n",
      "ADJ\t\t12477\t\t 6.1%\n",
      "AUX\t\t12343\t\t 6.0%\n",
      "ADV\t\t10548\t\t 5.2%\n",
      "CCONJ\t\t6707\t\t 3.3%\n",
      "PART\t\t5567\t\t 2.7%\n",
      "NUM\t\t3999\t\t 2.0%\n",
      "SCONJ\t\t3843\t\t 1.9%\n",
      "X\t\t847\t\t 0.4%\n",
      "INTJ\t\t688\t\t 0.3%\n",
      "SYM\t\t599\t\t 0.3%\n"
     ]
    }
   ],
   "source": [
    "def tag_percentage(tag_counts):\n",
    "    \n",
    "    total_count = sum([count for tag, count in tag_counts])\n",
    "    \n",
    "    tag_counts_percentages = [(tag, count, count/total_count) for tag, count in tag_counts]\n",
    "        \n",
    "    return tag_counts_percentages\n",
    "\n",
    "print(\"Tag\\t\\tCount\\t\\tPercentage\\n\")\n",
    "\n",
    "for tag, count, percent in tag_percentage(UD_TAGS.vocab.freqs.most_common()):\n",
    "    print(f\"{tag}\\t\\t{count}\\t\\t{percent*100:4.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e466493-8a34-4552-85a3-48d3ea36e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f393e4c7-2f9d-46fc-9bc7-b3a47d9d6c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMPOSTagger(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim, \n",
    "                 output_dim, \n",
    "                 n_layers, \n",
    "                 bidirectional, \n",
    "                 dropout, \n",
    "                 pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            num_layers = n_layers, \n",
    "                            bidirectional = bidirectional,\n",
    "                            dropout = dropout if n_layers > 1 else 0)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "                \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16760a14-e405-470a-9938-8a8d43dd67e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = len(UD_TAGS.vocab)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = BiLSTMPOSTagger(INPUT_DIM, \n",
    "                        EMBEDDING_DIM, \n",
    "                        HIDDEN_DIM, \n",
    "                        OUTPUT_DIM, \n",
    "                        N_LAYERS, \n",
    "                        BIDIRECTIONAL, \n",
    "                        DROPOUT, \n",
    "                        PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac4856a5-3290-49d9-b5dd-6a0ddf1bbc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,522,010 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
    "        \n",
    "model.apply(init_weights)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e78ba6b3-8279-493a-8ad6-50bb3b082354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8866, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
       "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [ 0.9261,  2.3049,  0.5502,  ..., -0.3492, -0.5298, -0.1577],\n",
       "        [-0.5972,  0.0471, -0.2406,  ..., -0.9446, -0.1126, -0.2260],\n",
       "        [-0.4809,  2.5629,  0.9530,  ...,  0.5278, -0.4588,  0.7294]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edf67ff4-9513-4ce6-adcc-f6ca17e74654",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80b411f8-75ca-454a-9e56-3d6b9d7b9276",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9aab586-2cd4-4682-bbd4-35c4dfee3edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "def categorical_accuracy(preds, y, tag_pad_idx):\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) \n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
    "    return correct.sum() / y[non_pad_elements].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7c4e579-2a12-4bc8-ba21-82f5d7aa1961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        text = batch.text\n",
    "        tags = batch.udtags\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions = model(text)\n",
    "        \n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "        \n",
    "        loss = criterion(predictions, tags)\n",
    "                \n",
    "        acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de766749-e02d-446e-a330-168b17a1024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text = batch.text\n",
    "            tags = batch.udtags\n",
    "            \n",
    "            predictions = model(text)\n",
    "            \n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "            \n",
    "            loss = criterion(predictions, tags)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffc752a4-d8af-430c-8367-bc9b55ab73eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48bdf647-848f-4203-9544-ed60169b0ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 2m 46s\n",
      "\tTrain Loss: 1.337 | Train Acc: 58.14%\n",
      "\t Val. Loss: 0.677 |  Val. Acc: 78.71%\n",
      "Epoch: 02 | Epoch Time: 2m 49s\n",
      "\tTrain Loss: 0.481 | Train Acc: 84.90%\n",
      "\t Val. Loss: 0.508 |  Val. Acc: 83.09%\n",
      "Epoch: 03 | Epoch Time: 2m 50s\n",
      "\tTrain Loss: 0.350 | Train Acc: 88.96%\n",
      "\t Val. Loss: 0.445 |  Val. Acc: 85.30%\n",
      "Epoch: 04 | Epoch Time: 2m 48s\n",
      "\tTrain Loss: 0.292 | Train Acc: 90.71%\n",
      "\t Val. Loss: 0.407 |  Val. Acc: 86.23%\n",
      "Epoch: 05 | Epoch Time: 2m 45s\n",
      "\tTrain Loss: 0.253 | Train Acc: 92.02%\n",
      "\t Val. Loss: 0.397 |  Val. Acc: 86.28%\n",
      "Epoch: 06 | Epoch Time: 2m 51s\n",
      "\tTrain Loss: 0.226 | Train Acc: 92.82%\n",
      "\t Val. Loss: 0.381 |  Val. Acc: 87.09%\n",
      "Epoch: 07 | Epoch Time: 2m 49s\n",
      "\tTrain Loss: 0.206 | Train Acc: 93.40%\n",
      "\t Val. Loss: 0.372 |  Val. Acc: 87.45%\n",
      "Epoch: 08 | Epoch Time: 2m 50s\n",
      "\tTrain Loss: 0.192 | Train Acc: 93.89%\n",
      "\t Val. Loss: 0.362 |  Val. Acc: 87.59%\n",
      "Epoch: 09 | Epoch Time: 2m 51s\n",
      "\tTrain Loss: 0.176 | Train Acc: 94.30%\n",
      "\t Val. Loss: 0.356 |  Val. Acc: 88.34%\n",
      "Epoch: 10 | Epoch Time: 2m 49s\n",
      "\tTrain Loss: 0.167 | Train Acc: 94.62%\n",
      "\t Val. Loss: 0.350 |  Val. Acc: 88.28%\n",
      "Test Loss: 0.365 |  Test Acc: 88.30%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, TAG_PAD_IDX)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac72652-d302-457d-bf3f-a5c895974a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sentence(model, device, sentence, text_field, tag_field):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "        tokens = [token.text for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token for token in sentence]\n",
    "\n",
    "    if text_field.lower:\n",
    "        tokens = [t.lower() for t in tokens]\n",
    "        \n",
    "    numericalized_tokens = [text_field.vocab.stoi[t] for t in tokens]\n",
    "\n",
    "    unk_idx = text_field.vocab.stoi[text_field.unk_token]\n",
    "    \n",
    "    unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]\n",
    "    \n",
    "    token_tensor = torch.LongTensor(numericalized_tokens)\n",
    "    \n",
    "    token_tensor = token_tensor.unsqueeze(-1).to(device)\n",
    "         \n",
    "    predictions = model(token_tensor)\n",
    "    \n",
    "    top_predictions = predictions.argmax(-1)\n",
    "    \n",
    "    predicted_tags = [tag_field.vocab.itos[t.item()] for t in top_predictions]\n",
    "    \n",
    "    return tokens, predicted_tags, unks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bac027e-bf01-44ab-93f6-890541af0fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'this', 'killing', 'of', 'a', 'respected', 'cleric', 'will', 'be', 'causing', 'us', 'trouble', 'for', 'years', 'to', 'come', '.', ']']\n"
     ]
    }
   ],
   "source": [
    "example_index = 1\n",
    "\n",
    "sentence = vars(train_data.examples[example_index])['text']\n",
    "actual_tags = vars(train_data.examples[example_index])['udtags']\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e675594d-242e-493d-8d83-c96361e16378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['respected', 'cleric']\n"
     ]
    }
   ],
   "source": [
    "tokens, pred_tags, unks = tag_sentence(model, \n",
    "                                       device, \n",
    "                                       sentence, \n",
    "                                       TEXT, \n",
    "                                       UD_TAGS)\n",
    "\n",
    "print(unks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d798d284-d3a9-464a-889b-a9503a9cf83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
      "\n",
      "PUNCT\t\tPUNCT\t\t✔\t\t[\n",
      "DET\t\tDET\t\t✔\t\tthis\n",
      "VERB\t\tNOUN\t\t✘\t\tkilling\n",
      "ADP\t\tADP\t\t✔\t\tof\n",
      "DET\t\tDET\t\t✔\t\ta\n",
      "ADJ\t\tADJ\t\t✔\t\trespected\n",
      "NOUN\t\tNOUN\t\t✔\t\tcleric\n",
      "AUX\t\tAUX\t\t✔\t\twill\n",
      "AUX\t\tAUX\t\t✔\t\tbe\n",
      "VERB\t\tVERB\t\t✔\t\tcausing\n",
      "PRON\t\tPRON\t\t✔\t\tus\n",
      "NOUN\t\tNOUN\t\t✔\t\ttrouble\n",
      "ADP\t\tADP\t\t✔\t\tfor\n",
      "NOUN\t\tNOUN\t\t✔\t\tyears\n",
      "PART\t\tPART\t\t✔\t\tto\n",
      "VERB\t\tVERB\t\t✔\t\tcome\n",
      "PUNCT\t\tPUNCT\t\t✔\t\t.\n",
      "PUNCT\t\tPUNCT\t\t✔\t\t]\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
    "\n",
    "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
    "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
    "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94343ca9-537c-44d0-97f0-7e21d7dabca3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRoses are read, I am dead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m tokens, pred_tags, unks \u001b[38;5;241m=\u001b[39m tag_sentence(\u001b[43mmodel\u001b[49m, \n\u001b[1;32m      3\u001b[0m                                        device, \n\u001b[1;32m      4\u001b[0m                                        sentence, \n\u001b[1;32m      5\u001b[0m                                        TEXT, \n\u001b[1;32m      6\u001b[0m                                        UD_TAGS)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpred_tag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtoken\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "sentence = \"Roses are read, I am dead\"\n",
    "tokens, pred_tags, unks = tag_sentence(model, \n",
    "                                       device, \n",
    "                                       sentence, \n",
    "                                       TEXT, \n",
    "                                       UD_TAGS)\n",
    "print(f\"{pred_tag}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a94a06-e76f-4beb-8319-600e3e2f1860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
